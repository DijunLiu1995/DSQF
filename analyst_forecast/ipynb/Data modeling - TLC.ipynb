{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines for model trainng @author Tim Copeland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class to select numerical columns\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        #add year_qnum column\n",
    "        #X['year_qnum'] = X['date'].apply(lambda x: int(str(x[0:4]) + str(X['qnum'])))\n",
    "        \n",
    "        #ret_X = X[X['year_qnum'] < target]\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGDClassifier with both hinge loss and log loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_earn_df = pd.read_csv('AFE_data/Training DFs_new/surprise_df1.csv')\n",
    "full_dist_df     = pd.read_csv('AFE_data/Training DFs_new/surprise_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'TICKER', 'quarternum', 'analyst', 'forecast_value',\n",
       "       'year', 'earn_value', 'std', 'Analyst_Counts', 'Max', 'Min',\n",
       "       'the max_forecast-min_forecast', 'delta_return', 'Y', 'Y_up', 'Y_down',\n",
       "       'quantile_0', 'quantile_10', 'quantile_20', 'quantile_30',\n",
       "       'quantile_40', 'quantile_50', 'quantile_60', 'quantile_70',\n",
       "       'quantile_80', 'quantile_90'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dist_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop y_up and y_down for now\n",
    "full_dist_df = full_dist_df.drop(['Y_up', 'Y_down'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop redundant index col\n",
    "surprise_earn_df = surprise_earn_df.drop(surprise_earn_df.columns[0], axis=1)\n",
    "full_dist_df = full_dist_df.drop(full_dist_df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace inf's with nan's\n",
    "#surprise_earn_df = surprise_earn_df.replace(np.inf, np.nan)\n",
    "#full_dist_df     = full_dist_df.replace(np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surprise_median_fa</th>\n",
       "      <th>surprise_mean_fa</th>\n",
       "      <th>TICKER</th>\n",
       "      <th>year</th>\n",
       "      <th>quarternum</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>delta_return</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.392305</td>\n",
       "      <td>9.814955</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.016738</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.0381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.392305</td>\n",
       "      <td>9.814955</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.016738</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.0381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.392305</td>\n",
       "      <td>9.814955</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.016738</td>\n",
       "      <td>0.83</td>\n",
       "      <td>-0.0381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ABBV</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surprise_median_fa  surprise_mean_fa TICKER  year  quarternum      Skew  \\\n",
       "0           10.392305          9.814955   ABBV  2015           0 -0.016738   \n",
       "1           10.392305          9.814955   ABBV  2015           0 -0.016738   \n",
       "2           10.392305          9.814955   ABBV  2015           0 -0.016738   \n",
       "3            0.000000          0.000000   ABBV  2016           2  0.000000   \n",
       "4            0.000000          0.000000   ABBV  2016           2  0.000000   \n",
       "\n",
       "   Kurtosis  delta_return  Y  \n",
       "0      0.83       -0.0381  0  \n",
       "1      0.83       -0.0381  0  \n",
       "2      0.83       -0.0381  0  \n",
       "3      1.26        0.0145  0  \n",
       "4      1.26        0.0145  0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_earn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TICKER</th>\n",
       "      <th>quarternum</th>\n",
       "      <th>analyst</th>\n",
       "      <th>forecast_value</th>\n",
       "      <th>year</th>\n",
       "      <th>earn_value</th>\n",
       "      <th>std</th>\n",
       "      <th>Analyst_Counts</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "      <th>...</th>\n",
       "      <th>quantile_0</th>\n",
       "      <th>quantile_10</th>\n",
       "      <th>quantile_20</th>\n",
       "      <th>quantile_30</th>\n",
       "      <th>quantile_40</th>\n",
       "      <th>quantile_50</th>\n",
       "      <th>quantile_60</th>\n",
       "      <th>quantile_70</th>\n",
       "      <th>quantile_80</th>\n",
       "      <th>quantile_90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>0</td>\n",
       "      <td>171887</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>0</td>\n",
       "      <td>109306</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>0</td>\n",
       "      <td>84063</td>\n",
       "      <td>0.83</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>3</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>2</td>\n",
       "      <td>105436</td>\n",
       "      <td>1.29</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>2</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBV</td>\n",
       "      <td>2</td>\n",
       "      <td>130921</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.042426</td>\n",
       "      <td>2</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  TICKER  quarternum  analyst  forecast_value  year  earn_value       std  \\\n",
       "0   ABBV           0   171887            0.83  2015        0.89  0.005774   \n",
       "1   ABBV           0   109306            0.84  2015        0.89  0.005774   \n",
       "2   ABBV           0    84063            0.83  2015        0.89  0.005774   \n",
       "3   ABBV           2   105436            1.29  2016        1.26  0.042426   \n",
       "4   ABBV           2   130921            1.23  2016        1.26  0.042426   \n",
       "\n",
       "   Analyst_Counts   Max   Min     ...       quantile_0  quantile_10  \\\n",
       "0               3  0.84  0.83     ...         0.666667          0.0   \n",
       "1               3  0.84  0.83     ...         0.666667          0.0   \n",
       "2               3  0.84  0.83     ...         0.666667          0.0   \n",
       "3               2  1.29  1.23     ...         0.500000          0.0   \n",
       "4               2  1.29  1.23     ...         0.500000          0.0   \n",
       "\n",
       "   quantile_20  quantile_30  quantile_40  quantile_50  quantile_60  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   quantile_70  quantile_80  quantile_90  \n",
       "0          0.0          0.0     0.333333  \n",
       "1          0.0          0.0     0.333333  \n",
       "2          0.0          0.0     0.333333  \n",
       "3          0.0          0.0     0.500000  \n",
       "4          0.0          0.0     0.500000  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a year + qnum column\n",
    "to_str = lambda x: str(x)\n",
    "to_int = lambda x: int(x)\n",
    "\n",
    "surprise_earn_df['year_qnum'] = surprise_earn_df['year'].apply(to_str) + surprise_earn_df['quarternum'].apply(to_str)\n",
    "surprise_earn_df['year_qnum'] = surprise_earn_df['year_qnum'].apply(to_int)\n",
    "\n",
    "full_dist_df['year_qnum']     = full_dist_df['year'].apply(to_str) + full_dist_df['quarternum'].apply(to_str)\n",
    "full_dist_df['year_qnum']     = full_dist_df['year_qnum'].apply(to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generates X and y trainng and test sets for a given df and year_qnum\n",
    "class analyst_forecasting_model:\n",
    "    #df is either the full_dist_df or the surprise_earn_df\n",
    "    def __init__(self,df, predictor):\n",
    "        self.df               = df\n",
    "        self.predictor        = predictor\n",
    "        \n",
    "        self.grid_fit         = [] #contains grid search fit paramaters for the quarter\n",
    "        #self.grid_fit_up      = []\n",
    "        #self.grid_fit_down    = []\n",
    "        \n",
    "        self.predictions      = [] #contains grid search best fit predictions for the quarter\n",
    "        #self.predictions_up   = []\n",
    "        #self.predictions_down = []\n",
    "        \n",
    "        self.missed           = [] #contains sum of missed predictions / total # predictions for the quarter\n",
    "        #self.missed_up        = []\n",
    "        #self.missed_down      = []\n",
    "        \n",
    "        self.pr_curve         = [] #precision recall curve\n",
    "    \n",
    "        #pre processes data \n",
    "        #self.full_pipeline = self.create_full_pipeline_with_predictor()\n",
    "        \n",
    "        self.full_pipeline = Pipeline([        \n",
    "            ('selector', DataFrameSelector()),\n",
    "            ('imputer1', Imputer(strategy=\"median\")),\n",
    "            ('imputer2', Imputer(missing_values = np.inf, strategy=\"median\")),\n",
    "            ('imputer3', Imputer(missing_values = -np.inf, strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler())\n",
    "        ])\n",
    "        \n",
    "    def run_all_quarters(self):\n",
    "        #need to skip first quarter because we don't have trainng data for it\n",
    "        for i in self.df['year_qnum'].unique()[1:-1]: \n",
    "            self.train_predict(i)\n",
    "    \n",
    "    def data_sets(self, year_qnum):\n",
    "        df = self.df\n",
    "        \n",
    "        #train and test data\n",
    "        X_train      = df[df['year_qnum'] < year_qnum]\n",
    "        y_train      = X_train['Y']\n",
    "        #y_train_up   = X_train['Y_up']\n",
    "        #y_train_down = X_train['Y_down']\n",
    "\n",
    "        #X_train = X_train.drop(['Y', 'Y_up', 'Y_down', 'year', 'TICKER', 'year_qnum'], axis=1)\n",
    "        X_train = X_train.drop(['Y', 'year', 'TICKER', 'year_qnum'], axis=1)\n",
    "\n",
    "        X_test      = df[df['year_qnum'] == year_qnum]\n",
    "        y_test      = X_test['Y']\n",
    "        #y_test_up   = X_test['Y_up']\n",
    "        #y_test_down = X_test['Y_down']\n",
    "        \n",
    "        #X_test = X_test.drop(['Y', 'Y_up', 'Y_down', 'year', 'TICKER', 'year_qnum'], axis=1)\n",
    "        X_test = X_test.drop(['Y', 'year', 'TICKER', 'year_qnum'], axis=1)\n",
    "        \n",
    "        #return X_train, y_train, y_train_up, y_train_down, \\\n",
    "        #       X_test, y_test, y_test_up, y_test_down\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "    \n",
    "    def train_predict(self,year_qnum):\n",
    "        #X_train, y_train, y_train_up, y_train_down, X_test, y_test, y_test_up, y_test_down \\\n",
    "        #            = self.data_sets(year_qnum)\n",
    "        \n",
    "        X_train, y_train, X_test, y_test = self.data_sets(year_qnum)\n",
    "        \n",
    "        param_grid = {\n",
    "            'classify__penalty':['l2', 'l1'],\n",
    "            'classify__alpha':[0.0001,0.0001*10,0.0001*100.],\n",
    "            'classify__l1_ratio':[.15,.3,.5,.7],\n",
    "        }\n",
    "        #--train + test\n",
    "        print(self.full_pipeline.fit_transform(X_train))\n",
    "                \n",
    "        grid_search = GridSearchCV(self.predictor, cv=3, n_jobs=1, param_grid=param_grid)\n",
    "        grid_search.fit(self.full_pipeline.fit_transform(X_train), y_train)\n",
    "        self.grid_fit.append(grid_search)\n",
    "    \n",
    "        \n",
    "        predict = grid_search.predict(X_test)\n",
    "        self.predictions.append(predict)\n",
    "        \n",
    "        y_score = classifier.decision_function(X_test)\n",
    "        average_precision = average_precision_score(y_test, y_score)\n",
    "        self.pr_curve.append(average_precision)\n",
    "        \n",
    "        miss    = sum(np.abs(y_test - predict))/len(y_test)\n",
    "        self.missed.append(miss)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        #--up train and test\n",
    "        grid_search = GridSearchCV(self.predictor, cv=3, n_jobs=1, param_grid=param_grid)\n",
    "        grid_search.fit(self.full_pipeline.fit_transform(X_train), y_train_up)\n",
    "        self.grid_fit.append(grid_search)\n",
    "    \n",
    "        \n",
    "        predict = grid_search.predict(X_train)\n",
    "        self.predictions.append(predict_up)\n",
    "        \n",
    "        missup    = sum(np.abs(y_test_up - predict))/len(y_test_up)\n",
    "        self.missed.append(miss_up)\n",
    "        \n",
    "        #down train and test\n",
    "        grid_search = GridSearchCV(self.predictor, cv=3, n_jobs=1, param_grid=param_grid)\n",
    "        grid_search.fit(self.full_pipeline.fit_transform(X_train), y_train_down)\n",
    "        self.grid_fit.append(grid_search)\n",
    "    \n",
    "        \n",
    "        predict = grid_search.predict(X_test_down)\n",
    "        self.predictions.append(predict_down)\n",
    "        \n",
    "        missup    = sum(np.abs(y_test_down - predict))/len(y_test_down)\n",
    "        self.missed.append(miss_up)\n",
    "        \"\"\"\n",
    "                \n",
    "    def run_describe_predictors(self,predictors, X, y):\n",
    "        res = pd.DataFrame()\n",
    "        for name, predictor in predictors.items():\n",
    "            pipe = self.create_full_pipeline_with_predictor(predictor)\n",
    "            scores = cross_val_score(pipe, X, y,scoring='neg_mean_squared_error', cv=5) #5-fold cross-validation\n",
    "            print(pd.Series(scores).describe())\n",
    "            print('')\n",
    "            res[str(name)] = pd.Series(scores).describe()\n",
    "        return res\n",
    "\n",
    "\n",
    "    def create_full_pipeline_with_predictor(self):\n",
    "        pipe = Pipeline([\n",
    "            (\"preparation\", self.full_pipeline),\n",
    "            (\"SGDClassifier\", self.predictor)\n",
    "        ])\n",
    "        return pipe\n",
    "\n",
    "    def run_describe_predictors(self,predictors, X, y):\n",
    "        res = pd.DataFrame()\n",
    "        for name, predictor in predictors.items():\n",
    "            pipe = create_full_pipeline_with_predictor(predictor)\n",
    "            scores = cross_val_score(pipe, X, y,scoring='neg_mean_squared_error', cv=5) #5-fold cross-validation\n",
    "            print(pd.Series(scores).describe())\n",
    "            print('')\n",
    "            res[str(name)] = pd.Series(scores).describe()\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00055742  0.9325602  -1.26912758 -0.09905152  0.27003852 -0.61147229]\n",
      " [ 1.00055742  0.9325602  -1.26912758 -0.09905152  0.27003852 -0.61147229]\n",
      " [ 1.00055742  0.9325602  -1.26912758 -0.09905152  0.27003852 -0.61147229]\n",
      " ..., \n",
      " [ 0.31468851  0.30978217 -1.26912758 -0.05589352 -0.56705026  0.39748833]\n",
      " [-0.05534561 -0.04522838 -1.26912758 -0.05589352 -0.57533827  0.31126531]\n",
      " [-0.05534561 -0.04522838 -0.3753188  -0.05589352 -0.34327406  0.54270606]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, {'SGD_log': SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False)} was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-16a09ba0f7cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'SGD_log'\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'log'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyst_forecasting_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msurprise_earn_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_all_quarters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-3f857e19337d>\u001b[0m in \u001b[0;36mrun_all_quarters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[1;31m#need to skip first quarter because we don't have trainng data for it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'year_qnum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdata_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear_qnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-3f857e19337d>\u001b[0m in \u001b[0;36mtrain_predict\u001b[0;34m(self, year_qnum)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_fit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\tcope\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         scorers, self.multimetric_ = _check_multimetric_scoring(\n\u001b[0;32m--> 595\u001b[0;31m             self.estimator, scoring=self.scoring)\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultimetric_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\tcope\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_check_multimetric_scoring\u001b[0;34m(estimator, scoring)\u001b[0m\n\u001b[1;32m    340\u001b[0m     if callable(scoring) or scoring is None or isinstance(scoring,\n\u001b[1;32m    341\u001b[0m                                                           six.string_types):\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\users\\tcope\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0;32m--> 274\u001b[0;31m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0m\u001b[1;32m    275\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, {'SGD_log': SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n       shuffle=True, tol=None, verbose=0, warm_start=False)} was passed"
     ]
    }
   ],
   "source": [
    "predictor = {'SGD_log':  SGDClassifier(loss = 'log')}\n",
    "a = analyst_forecasting_model(surprise_earn_df, predictor)\n",
    "a.run_all_quarters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = {'SGD_hinge':SGDClassifier()}\n",
    "a = analyst_forecasting_model(surprise_earn_df, predictor)\n",
    "a.run_all_quarters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
