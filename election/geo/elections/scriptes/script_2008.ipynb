{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Election Data 2008 from NYT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is used to gather data from NYT's website for election 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function which get the map between candidate and party\n",
    "def getPartyMap(state_soup):\n",
    "    partyMap = {}\n",
    "    map_table = state_soup.find_all('table',{'id':'presidential-results-table'})[0]\n",
    "    column_name = [column.get_text().strip() for column in map_table.find_all('tr')[0].find_all('th')[0:2]]\n",
    "    for row in map_table.find_all('tbody')[0].find_all('tr'):\n",
    "        name = row.find_all('th')[0].get_text().strip().split(' ')[-1].replace('\"','')\n",
    "        party = row.find_all('td',{'class':'party'})[0].get_text().strip()\n",
    "        if party == 'Dem.':\n",
    "            party = 'D'\n",
    "        elif party == 'Rep.':\n",
    "            party = 'R'\n",
    "        else:\n",
    "            party = 'O'\n",
    "        partyMap[name] = party\n",
    "    return partyMap\n",
    "\n",
    "# Generate data row for each county\n",
    "def getContentForState(state_name, state_soup, state_county_soup):\n",
    "    county_result = state_county_soup.find_all('table',{'id': 'winners-by-county-table'})[0]\n",
    "    candidate = [name.get_text().strip() for name in county_result.find_all('tr')[0].find_all('th')[1:3]]\n",
    "    partyMap = getPartyMap(state_soup)\n",
    "\n",
    "    county_party = [partyMap[this_cand] for this_cand in candidate]\n",
    "\n",
    "    county_stat = county_result.find_all('tr')[1:]\n",
    "\n",
    "    raw_data = pd.DataFrame(columns = column_Name) \n",
    "    for this_county in county_stat:\n",
    "        this_county_data = this_county.find_all('td')\n",
    "        county_name = this_county_data[0].get_text().strip()\n",
    "        county_pct = [float(num.get_text().strip().split('%')[0]) for num in this_county_data[1:4:2]]\n",
    "        county_vote = [int(num.get_text().strip().replace(',','').replace('votes','')) for num in this_county_data[2::2]]\n",
    "        sort_index = [b[0] for b in sorted(enumerate(county_vote),key=lambda i:i[1], reverse=True)]\n",
    "        ordered_candidate = [candidate[i] for i in sort_index]\n",
    "        county_vote = [county_vote[i] for i in sort_index]\n",
    "        county_pct = [county_pct[i] for i in sort_index]\n",
    "        ordered_county_party = [county_party[i] for i in sort_index]\n",
    "    \n",
    "\n",
    "        if len(ordered_candidate) < 3:\n",
    "            ordered_candidate = ordered_candidate+[None]*(3-len(ordered_candidate))\n",
    "            county_vote = county_vote + [None]*(3-len(county_vote))\n",
    "            county_pct = county_pct + [None]*(3-len(county_pct))\n",
    "            ordered_county_party = ordered_county_party + [None]*(3-len(ordered_county_party))\n",
    "\n",
    "        this_record = [state_name, county_name] + ordered_candidate + county_vote + county_pct + ordered_county_party\n",
    "\n",
    "        raw_data = raw_data.append(pd.DataFrame([this_record], columns= column_Name))\n",
    "    \n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_Name = ['state','county', '1st', '2nd', '3rd', 'votes1', 'votes2', 'votes3', 'pct1', 'pct2', 'pct3', 'party1', 'party2', 'party3']\n",
    "\n",
    "state_name = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', \n",
    "              'District_of_Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', \n",
    "              'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', \n",
    "              'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New_Hampshire', 'New_Jersey', 'New_Mexico', \n",
    "              'New_York', 'North_Carolina', 'North_Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', \n",
    "              'Rhode_Island', 'South_Carolina', 'South_Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', \n",
    "              'Washington', 'West_Virginia', 'Wisconsin', 'Wyoming']\n",
    "\n",
    "# Remove the state which doesn't provide county data\n",
    "county_data_exist = [1]*len(state_name)\n",
    "county_data_exist[1] = 0\n",
    "county_data_exist[8] = 0\n",
    "\n",
    "county_exist = {key: value for (key, value) in zip(state_name, county_data_exist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_2008 = pd.DataFrame(columns = column_Name) \n",
    "\n",
    "# Loop through each state to get the data\n",
    "for state in state_name:\n",
    "    \n",
    "    if county_exist[state] == 0:\n",
    "        continue\n",
    "    state_name = state.replace('_', ' ')\n",
    "    state = state.lower().replace('_','-')\n",
    "    state_url = 'https://www.nytimes.com/elections/2008/results/states/' + state + '.html'\n",
    "    ua = UserAgent()\n",
    "    header = {'User-Agent':str(ua.chrome)}\n",
    "    htmlContent = requests.get(state_url, headers=header)\n",
    "    state_soup = BeautifulSoup(htmlContent.text, 'html.parser')\n",
    "\n",
    "    state_county_url = 'https://www.nytimes.com/elections/2008/results/states/president/' + state + '.html'\n",
    "\n",
    "    ua = UserAgent()\n",
    "    header = {'User-Agent':str(ua.chrome)}\n",
    "    htmlContent = requests.get(state_county_url, headers=header)\n",
    "    state_county_soup = BeautifulSoup(htmlContent.text, 'html.parser')\n",
    "\n",
    "    \n",
    "    all_data_2008 = all_data_2008.append(getContentForState(state_name, state_soup, state_county_soup))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_2008.to_csv('2008.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
